# Getting Started with MERIT

Welcome to MERIT! This section will help you get started with the MERIT package, understand its key concepts, and begin implementing evaluation workflows for your AI systems.

## In This Section

- [Introduction](./01_introduction.md): Learn about MERIT and its capabilities
- [Installation](./02_installation.md): Instructions for installing MERIT
- [Key Concepts](./03_key_concepts.md): Core concepts and terminology used in MERIT
- [Quick Start](./04_quick_start.md): A simple example to get you up and running quickly

## What is MERIT?

MERIT (Monitoring, Evaluation, Reporting, Inspection, Testing) is a comprehensive framework for evaluating and testing AI systems, particularly those powered by Large Language Models (LLMs). It provides tools and utilities to help you implement rigorous evaluation and testing workflows for your AI applications.

## Who Should Use MERIT?

MERIT is designed for:

- **AI Engineers** who need to evaluate and test LLM-powered applications
- **Data Scientists** who want to measure the performance of AI systems
- **Researchers** who need to benchmark different AI approaches
- **Product Managers** who need to understand AI system capabilities and limitations

## Key Features

- Generate comprehensive test sets for evaluating AI systems
- Connect to various AI APIs with a unified interface
- Evaluate AI systems using customizable metrics
- Measure performance across various dimensions
- Work with document collections for RAG evaluation

## Next Steps

Start by reading the [Introduction](./01_introduction.md) to learn more about MERIT and its capabilities. Then, follow the [Installation](./02_installation.md) guide to set up MERIT in your environment. Once installed, check out the [Quick Start](./04_quick_start.md) guide to see MERIT in action.

For a deeper understanding of MERIT's concepts and terminology, refer to the [Key Concepts](./03_key_concepts.md) guide.
